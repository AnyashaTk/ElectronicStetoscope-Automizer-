{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class HeartAudioDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None, sample_rate=22050, duration=60):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.sample_rate = sample_rate\n",
    "        self.duration = duration\n",
    "        self.max_len = sample_rate * duration\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        waveform, sr = torchaudio.load(self.file_paths[idx])\n",
    "\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "        if waveform.shape[1] > self.max_len:\n",
    "            waveform = waveform[:, :self.max_len]\n",
    "        else:\n",
    "            pad = self.max_len - waveform.shape[1]\n",
    "            waveform = torch.nn.functional.pad(waveform, (0, pad))\n",
    "\n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "        return waveform, torch.tensor(self.labels[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_cdpd = '../data/CDPD/training_data/'\n",
    "\n",
    "def load_cdpd_paths(file_names):\n",
    "    paths = []\n",
    "    for file_name in tqdm(file_names):\n",
    "        paths.append(f\"{directory_cdpd}{file_name}_combined.wav\")\n",
    "    return paths\n",
    "\n",
    "def load_acd_paths(directory):\n",
    "    paths = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                paths.append(os.path.join(root, file))\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cdpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load paths and labels\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../data/CDPD/training_data.csv') \n",
    "df = df[df['Locations'].isin(['AV+PV+TV+MV', 'AV+PV+MV', 'AV+AV+PV+PV+TV+MV', 'AV+MV+MV', \n",
    "                                        'AV+PV+MV+Phc+Phc', 'AV+PV+TV+TV+MV', 'AV+AV+MV+MV', 'AV+AV+PV+TV+MV', 'AV+PV+TV+MV+Phc', 'AV+AV+AV+MV', 'AV+AV+PV+TV+MV+MV', ])&(df['Murmur']!='Unknown')]\n",
    "# df[df['Patient ID']==50321]\n",
    "df = df.drop([266])\n",
    "# df[df['Patient ID']==50321]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Locations</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Pregnancy status</th>\n",
       "      <th>Murmur</th>\n",
       "      <th>Murmur locations</th>\n",
       "      <th>Most audible location</th>\n",
       "      <th>...</th>\n",
       "      <th>Systolic murmur grading</th>\n",
       "      <th>Systolic murmur pitch</th>\n",
       "      <th>Systolic murmur quality</th>\n",
       "      <th>Diastolic murmur timing</th>\n",
       "      <th>Diastolic murmur shape</th>\n",
       "      <th>Diastolic murmur grading</th>\n",
       "      <th>Diastolic murmur pitch</th>\n",
       "      <th>Diastolic murmur quality</th>\n",
       "      <th>Campaign</th>\n",
       "      <th>Additional ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2530</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>98.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>False</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9979</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>103.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>AV+MV+PV+TV</td>\n",
       "      <td>TV</td>\n",
       "      <td>...</td>\n",
       "      <td>III/VI</td>\n",
       "      <td>High</td>\n",
       "      <td>Harsh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13918</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>98.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>TV</td>\n",
       "      <td>TV</td>\n",
       "      <td>...</td>\n",
       "      <td>I/VI</td>\n",
       "      <td>Low</td>\n",
       "      <td>Blowing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14241</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>87.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>AV+MV+PV+TV</td>\n",
       "      <td>PV</td>\n",
       "      <td>...</td>\n",
       "      <td>II/VI</td>\n",
       "      <td>Low</td>\n",
       "      <td>Harsh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14998</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>85337</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>130.0</td>\n",
       "      <td>27.3</td>\n",
       "      <td>False</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>85338</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>85340</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>105.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>False</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>85341</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>92.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>False</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>85343</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>97.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>MV+TV</td>\n",
       "      <td>TV</td>\n",
       "      <td>...</td>\n",
       "      <td>I/VI</td>\n",
       "      <td>Low</td>\n",
       "      <td>Blowing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>594 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Patient ID    Locations    Age     Sex  Height  Weight  Pregnancy status  \\\n",
       "0          2530  AV+PV+TV+MV  Child  Female    98.0    15.9             False   \n",
       "1          9979  AV+PV+TV+MV  Child  Female   103.0    13.1             False   \n",
       "3         13918  AV+PV+TV+MV  Child    Male    98.0    15.9             False   \n",
       "4         14241  AV+PV+TV+MV  Child    Male    87.0    11.2             False   \n",
       "5         14998  AV+PV+TV+MV  Child    Male     NaN     NaN             False   \n",
       "..          ...          ...    ...     ...     ...     ...               ...   \n",
       "934       85337  AV+PV+TV+MV  Child    Male   130.0    27.3             False   \n",
       "935       85338  AV+PV+TV+MV    NaN  Female     NaN     NaN              True   \n",
       "937       85340  AV+PV+TV+MV  Child    Male   105.0    16.6             False   \n",
       "938       85341  AV+PV+TV+MV  Child    Male    92.0    15.2             False   \n",
       "939       85343  AV+PV+TV+MV  Child  Female    97.0    13.5             False   \n",
       "\n",
       "      Murmur Murmur locations Most audible location  ...  \\\n",
       "0     Absent              NaN                   NaN  ...   \n",
       "1    Present      AV+MV+PV+TV                    TV  ...   \n",
       "3    Present               TV                    TV  ...   \n",
       "4    Present      AV+MV+PV+TV                    PV  ...   \n",
       "5     Absent              NaN                   NaN  ...   \n",
       "..       ...              ...                   ...  ...   \n",
       "934   Absent              NaN                   NaN  ...   \n",
       "935   Absent              NaN                   NaN  ...   \n",
       "937   Absent              NaN                   NaN  ...   \n",
       "938   Absent              NaN                   NaN  ...   \n",
       "939  Present            MV+TV                    TV  ...   \n",
       "\n",
       "    Systolic murmur grading Systolic murmur pitch Systolic murmur quality  \\\n",
       "0                       NaN                   NaN                     NaN   \n",
       "1                    III/VI                  High                   Harsh   \n",
       "3                      I/VI                   Low                 Blowing   \n",
       "4                     II/VI                   Low                   Harsh   \n",
       "5                       NaN                   NaN                     NaN   \n",
       "..                      ...                   ...                     ...   \n",
       "934                     NaN                   NaN                     NaN   \n",
       "935                     NaN                   NaN                     NaN   \n",
       "937                     NaN                   NaN                     NaN   \n",
       "938                     NaN                   NaN                     NaN   \n",
       "939                    I/VI                   Low                 Blowing   \n",
       "\n",
       "    Diastolic murmur timing Diastolic murmur shape Diastolic murmur grading  \\\n",
       "0                       NaN                    NaN                      NaN   \n",
       "1                       NaN                    NaN                      NaN   \n",
       "3                       NaN                    NaN                      NaN   \n",
       "4                       NaN                    NaN                      NaN   \n",
       "5                       NaN                    NaN                      NaN   \n",
       "..                      ...                    ...                      ...   \n",
       "934                     NaN                    NaN                      NaN   \n",
       "935                     NaN                    NaN                      NaN   \n",
       "937                     NaN                    NaN                      NaN   \n",
       "938                     NaN                    NaN                      NaN   \n",
       "939                     NaN                    NaN                      NaN   \n",
       "\n",
       "    Diastolic murmur pitch Diastolic murmur quality Campaign Additional ID  \n",
       "0                      NaN                      NaN   CC2015           NaN  \n",
       "1                      NaN                      NaN   CC2015           NaN  \n",
       "3                      NaN                      NaN   CC2015           NaN  \n",
       "4                      NaN                      NaN   CC2015           NaN  \n",
       "5                      NaN                      NaN   CC2015           NaN  \n",
       "..                     ...                      ...      ...           ...  \n",
       "934                    NaN                      NaN   CC2015           NaN  \n",
       "935                    NaN                      NaN   CC2015           NaN  \n",
       "937                    NaN                      NaN   CC2015           NaN  \n",
       "938                    NaN                      NaN   CC2015           NaN  \n",
       "939                    NaN                      NaN   CC2015           NaN  \n",
       "\n",
       "[594 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/594 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 594/594 [00:00<00:00, 3141761.13it/s]\n"
     ]
    }
   ],
   "source": [
    "file_names_cdpd = list(df['Patient ID']) # 0 - normal, 1 - patology\n",
    "cdpd_paths = load_cdpd_paths(file_names_cdpd)\n",
    "\n",
    "cdpd_labels = list(df['Murmur'].apply(lambda x: 0 if x=='Absent' else 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### acd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = \"../data/Пациенты.csv\"\n",
    "norm_dir = \"../data/норма\"\n",
    "patology_dir = \"../data/патология\"\n",
    "\n",
    "cda_paths = load_acd_paths(norm_dir)\n",
    "norm = len(cda_paths)\n",
    "cda_paths.extend(load_acd_paths(patology_dir))\n",
    "patology = len(cda_paths) - norm\n",
    "\n",
    "cda_labels = [0]* norm + [1] * patology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cdpd_paths, cdpd_labels, test_size=0.2, random_state=42)\n",
    "X_train_cda, X_test_cda, y_train_cda, y_test_cda = train_test_split(cda_paths, cda_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "X_train_cdpd_cda = X_train + X_train_cda\n",
    "y_train_cdpd_cda = y_train + y_train_cda\n",
    "X_test_cdpd_cda = X_test + X_test_cda\n",
    "y_test_cdpd_cda = y_test + y_test_cda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from binary_datasets_ import HeartSoundDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = (X_train_cdpd_cda, y_train_cdpd_cda)\n",
    "# val_dataset = HeartAudioDataset(X_test_cdpd_cda,y_test_cdpd_cda)HeartAudioDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SR = 16000\n",
    "MAX_DURATION_SEC = 30 # Максимальная длина для обработки\n",
    "N_MELS = 64 # Для примера, ResNet18 не очень глубокий, много мел-компонент может быть избыточно\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_resnet = HeartSoundDataset(\n",
    "        audio_paths=X_train_cdpd_cda,\n",
    "        labels=y_train_cdpd_cda,\n",
    "        target_sample_rate=TARGET_SR,\n",
    "        max_duration_seconds=MAX_DURATION_SEC,\n",
    "        n_mels=N_MELS,\n",
    "        n_fft=N_FFT,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        resnet_mode=True\n",
    "    )\n",
    "val_dataset_resnet = HeartSoundDataset(\n",
    "        audio_paths=X_test_cdpd_cda,\n",
    "        labels=y_test_cdpd_cda,\n",
    "        target_sample_rate=TARGET_SR,\n",
    "        max_duration_seconds=MAX_DURATION_SEC,\n",
    "        n_mels=N_MELS,\n",
    "        n_fft=N_FFT,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        resnet_mode=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_bilstm = HeartSoundDataset(\n",
    "        audio_paths=X_train_cdpd_cda,\n",
    "        labels=y_train_cdpd_cda,\n",
    "        target_sample_rate=TARGET_SR,\n",
    "        max_duration_seconds=MAX_DURATION_SEC,\n",
    "        n_mels=N_MELS,\n",
    "        n_fft=N_FFT,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        resnet_mode=False # Важно для BiLSTM\n",
    "    )\n",
    "val_dataset_bilstm = HeartSoundDataset(\n",
    "        audio_paths=X_test_cdpd_cda,\n",
    "        labels=y_test_cdpd_cda,\n",
    "        target_sample_rate=TARGET_SR,\n",
    "        max_duration_seconds=MAX_DURATION_SEC,\n",
    "        n_mels=N_MELS,\n",
    "        n_fft=N_FFT,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        resnet_mode=False # Важно для BiLSTM\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset_resnet, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset_resnet, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lstm_loader = DataLoader(train_dataset_bilstm, batch_size=64, shuffle=True)\n",
    "val_lstm_loader = DataLoader(val_dataset_bilstm, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10, name='', lr=1e-4):\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss() # ммм блин ладно справедливо конкретный лосс тут скорее придирка\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            preds = model(x_batch)\n",
    "            loss = criterion(preds, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Валидация\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val in val_loader:\n",
    "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "                outputs = model(x_val)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                correct += (preds == y_val).sum().item()\n",
    "                total += y_val.size(0)\n",
    "        acc = correct / total\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Val Acc: {acc:.4f}\")\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model.state_dict(), f\"./models/best_{name}_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def specificity_score(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if cm.shape == (2, 2):\n",
    "        tn, fp = cm[0, 0], cm[0, 1]\n",
    "        return tn / (tn + fp + 1e-10)\n",
    "    return 0\n",
    "\n",
    "def evaluate_model(model, dataloader, name, num_classes=2):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            out = model(x)\n",
    "            pred = torch.argmax(out, dim=1)\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    prec = precision_score(all_labels, all_preds, average='macro')\n",
    "    rec = recall_score(all_labels, all_preds, average='macro')\n",
    "    spec = specificity_score(all_labels, all_preds)\n",
    "    return {\"Model\": name, \"Accuracy\": acc, \"F1\": f1, \"Precision\": prec, \"Recall\": rec, \"Specificity\": spec}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model_path, audio_path, num_classes=2):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = HeartSoundResNet(num_classes=num_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    waveform, sr = torchaudio.load(audio_path)\n",
    "    mel_spec = T.MelSpectrogram(sample_rate=sr, n_mels=128)(waveform)\n",
    "    mel_spec = mel_spec[:, :, :500]  # ограничим длину\n",
    "    mel_spec = mel_spec.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(mel_spec)\n",
    "        pred = torch.argmax(output, dim=1).item()\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_all(models, train_loader, val_loader, num_classes=2, epochs=10):\n",
    "    results = []\n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        # model.load_state_dict(torch.load(f\"./models/best_{name}_model.pth\"))\n",
    "        train_model(model, train_loader, val_loader, num_epochs=epochs, name=name)\n",
    "        model.load_state_dict(torch.load(f\"./models/best_{name}_model.pth\"))  # можно переименовать\n",
    "        result = evaluate_model(model, val_loader, name, num_classes=num_classes)\n",
    "        results.append(result)\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_models import  HeartSoundResNet, HeartSoundBiLSTM, AttentionCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'HeartSoundResNet': HeartSoundResNet(),#HeartSoundResNet(),\n",
    "    # 'HeartSoundBiLSTM': HeartSoundBiLSTM(),\n",
    "    # 'AttentionCNN': AttentionCNN(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HeartSoundResNet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:25<12:46, 85.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Val Acc: 0.7846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [02:42<10:45, 80.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [03:53<08:52, 76.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Val Acc: 0.8308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [05:23<08:09, 81.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [06:51<06:59, 83.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Val Acc: 0.8846\n"
     ]
    }
   ],
   "source": [
    "results = train_and_evaluate_all(models, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HeartSoundBiLSTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [01:14<23:26, 74.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Val Acc: 0.7231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [02:29<22:28, 74.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Val Acc: 0.7231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [03:34<19:55, 70.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Val Acc: 0.7231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [04:55<19:55, 74.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Val Acc: 0.7231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [06:06<18:17, 73.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Val Acc: 0.7231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [07:28<17:47, 76.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Val Acc: 0.7231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [08:53<17:07, 79.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Val Acc: 0.7231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [09:03<16:49, 77.64s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mtrain_and_evaluate_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mHeartSoundBiLSTM\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mHeartSoundBiLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_lstm_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_lstm_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mtrain_and_evaluate_all\u001b[39m\u001b[34m(models, train_loader, val_loader, num_classes, epochs)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models.items():\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     model.load_state_dict(torch.load(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m./models/best_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_model.pth\u001b[39m\u001b[33m\"\u001b[39m))  \u001b[38;5;66;03m# можно переименовать\u001b[39;00m\n\u001b[32m      7\u001b[39m     result = evaluate_model(model, val_loader, name, num_classes=num_classes)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, num_epochs, name, lr)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs)):\n\u001b[32m     15\u001b[39m     model.train()\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/stetoscope/ElectronicStetoscope-Automizer-/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/stetoscope/ElectronicStetoscope-Automizer-/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/stetoscope/ElectronicStetoscope-Automizer-/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/stetoscope/ElectronicStetoscope-Automizer-/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/stetoscope/ElectronicStetoscope-Automizer-/notebooks/binary_datasets_.py:221\u001b[39m, in \u001b[36mHeartSoundDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m temp_waveform_for_librosa.ndim == \u001b[32m1\u001b[39m: \u001b[38;5;66;03m# Должен быть 1D для librosa\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m random.random() < \u001b[32m0.5\u001b[39m: \u001b[38;5;66;03m# PitchShift\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m         temp_waveform_for_librosa = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpitchshift_augmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_waveform_for_librosa\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.squeeze(\u001b[32m0\u001b[39m) \u001b[38;5;66;03m# Добавляем и убираем канал\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# TimeStretch\u001b[39;00m\n\u001b[32m    223\u001b[39m         temp_waveform_for_librosa = \u001b[38;5;28mself\u001b[39m.timestretch_augmentation(temp_waveform_for_librosa.unsqueeze(\u001b[32m0\u001b[39m)).squeeze(\u001b[32m0\u001b[39m) \u001b[38;5;66;03m# Добавляем и убираем канал\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/stetoscope/ElectronicStetoscope-Automizer-/notebooks/binary_datasets_.py:57\u001b[39m, in \u001b[36mPitchShift.__call__\u001b[39m\u001b[34m(self, samples)\u001b[39m\n\u001b[32m     55\u001b[39m n_steps = random.uniform(\u001b[38;5;28mself\u001b[39m.n_steps_range[\u001b[32m0\u001b[39m], \u001b[38;5;28mself\u001b[39m.n_steps_range[\u001b[32m1\u001b[39m])\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# librosa.effects.pitch_shift работает с NumPy массивами\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m shifted_samples_np = \u001b[43mlibrosa\u001b[49m\u001b[43m.\u001b[49m\u001b[43meffects\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpitch_shift\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43msamples_np\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Удаляем размерность канала, если она есть\u001b[39;49;00m\n\u001b[32m     58\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m                                                 \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Возвращаем в формат тензора PyTorch и добавляем размерность канала\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.from_numpy(shifted_samples_np).unsqueeze(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/stetoscope/ElectronicStetoscope-Automizer-/.venv/lib/python3.11/site-packages/librosa/util/decorators.py:88\u001b[39m, in \u001b[36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m extra_args = \u001b[38;5;28mlen\u001b[39m(args) - \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extra_args <= \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[32m     91\u001b[39m args_msg = [\n\u001b[32m     92\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(name, arg)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[-extra_args:])\n\u001b[32m     94\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/stetoscope/ElectronicStetoscope-Automizer-/.venv/lib/python3.11/site-packages/librosa/effects.py:327\u001b[39m, in \u001b[36mpitch_shift\u001b[39m\u001b[34m(y, sr, n_steps, bins_per_octave, res_type, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m rate = \u001b[32m2.0\u001b[39m ** (-\u001b[38;5;28mfloat\u001b[39m(n_steps) / bins_per_octave)\n\u001b[32m    326\u001b[39m \u001b[38;5;66;03m# Stretch in time, then resample\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m y_shift = \u001b[43mcore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_stretch\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43morig_sr\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mres_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mres_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[38;5;66;03m# Crop to the same dimension as the input\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m util.fix_length(y_shift, size=y.shape[-\u001b[32m1\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/stetoscope/ElectronicStetoscope-Automizer-/.venv/lib/python3.11/site-packages/librosa/util/decorators.py:88\u001b[39m, in \u001b[36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m extra_args = \u001b[38;5;28mlen\u001b[39m(args) - \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extra_args <= \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[32m     91\u001b[39m args_msg = [\n\u001b[32m     92\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(name, arg)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[-extra_args:])\n\u001b[32m     94\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/stetoscope/ElectronicStetoscope-Automizer-/.venv/lib/python3.11/site-packages/librosa/core/audio.py:647\u001b[39m, in \u001b[36mresample\u001b[39m\u001b[34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[39m\n\u001b[32m    645\u001b[39m     y_hat = soxr.resample(y.T, orig_sr, target_sr, quality=res_type).T\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m     y_hat = \u001b[43mresampy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_sr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mres_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fix:\n\u001b[32m    650\u001b[39m     y_hat = util.fix_length(y_hat, size=n_samples, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/stetoscope/ElectronicStetoscope-Automizer-/.venv/lib/python3.11/site-packages/resampy/core.py:168\u001b[39m, in \u001b[36mresample\u001b[39m\u001b[34m(x, sr_orig, sr_new, axis, filter, parallel, **kwargs)\u001b[39m\n\u001b[32m    158\u001b[39m         resample_f_s(\n\u001b[32m    159\u001b[39m             x.swapaxes(-\u001b[32m1\u001b[39m, axis),\n\u001b[32m    160\u001b[39m             t_out,\n\u001b[32m   (...)\u001b[39m\u001b[32m    165\u001b[39m             y.swapaxes(-\u001b[32m1\u001b[39m, axis),\n\u001b[32m    166\u001b[39m         )\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m     \u001b[43mresample_f_s\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mswapaxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterp_win\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterp_delta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mswapaxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/stetoscope/ElectronicStetoscope-Automizer-/.venv/lib/python3.11/site-packages/numba/np/ufunc/gufunc.py:288\u001b[39m, in \u001b[36mGUFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m         \u001b[38;5;28mself\u001b[39m.add(sig)\n\u001b[32m    286\u001b[39m     \u001b[38;5;28mself\u001b[39m.build_ufunc()\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "results = train_and_evaluate_all({'HeartSoundBiLSTM': HeartSoundBiLSTM()}, train_lstm_loader, val_lstm_loader, epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
